{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "try:\n",
    "    current_dir = os.path.dirname(__file__)\n",
    "except NameError:\n",
    "    current_dir = os.getcwd()  # Fallback to the current working directory\n",
    "\n",
    "src_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# Now import the module from utils\n",
    "from src.utils.etl import ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting Data:\n",
    "\n",
    "rating = 1 for every shiur in database. Can make something more advanced later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24677, 11)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = ETL()\n",
    "df = db.get_bookmakrs_df()\n",
    "df['rating'] = 1\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fastai DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>shiur</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80580.0</td>\n",
       "      <td>1024228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79212.0</td>\n",
       "      <td>955116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221467.0</td>\n",
       "      <td>1079301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92378.0</td>\n",
       "      <td>1099483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211439.0</td>\n",
       "      <td>1065734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35049.0</td>\n",
       "      <td>1012650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>209914.0</td>\n",
       "      <td>869348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>218322.0</td>\n",
       "      <td>889236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>212079.0</td>\n",
       "      <td>878883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10794.0</td>\n",
       "      <td>1098888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.collab import *\n",
    "\n",
    "dls = CollabDataLoaders.from_df(df, user_name='user', item_name='shiur', rating_name='rating', bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.459713</td>\n",
       "      <td>0.455195</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.418023</td>\n",
       "      <td>0.417283</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.387775</td>\n",
       "      <td>0.394726</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.376714</td>\n",
       "      <td>0.386109</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.373993</td>\n",
       "      <td>0.384774</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "learn = collab_learner(dls, n_factors=5, y_range=(0, 1), loss_func=BCEWithLogitsLossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('saved_models/user_collab_filtering_v1.pth')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model_dir = \"saved_models/\"\n",
    "learn.save(\"user_collab_filtering_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from base import BaseModel\n",
    "\n",
    "\n",
    "\n",
    "class UserCollabFilteringV1(BaseModel):\n",
    "    def __init__(self):\n",
    "        model = learn.load(\"user_collab_filtering_v1\")\n",
    "\n",
    "    def get_recommendations(self, user_id: str = None, *args, **kwargs) -> List[int]:\n",
    "        top_n = kwargs.get('top_n', 10)\n",
    "        user_id = int(float(user_id))\n",
    "        item_ids = dls.classes['shiur'].items[1:] # to avoid the na value\n",
    "        item_ids = [int(item_id) for item_id in item_ids]\n",
    "        user_tensor = torch.tensor([user_id] * len(item_ids)).unsqueeze(1)\n",
    "        item_tensor = torch.tensor(item_ids).unsqueeze(1)\n",
    "        input_tensor = torch.cat((user_tensor, item_tensor), dim=1)\n",
    "        \n",
    "        # Get predictions\n",
    "        input_df = pd.DataFrame(input_tensor.numpy(), columns=['user', 'shiur'])\n",
    "        user_item_dl = dls.test_dl(input_df)\n",
    "        preds, _ = learn.get_preds(dl=user_item_dl)\n",
    "        \n",
    "        # Get top N recommendations\n",
    "        top_indices = torch.argsort(preds, descending=True)[:top_n]\n",
    "        top_item_ids = [item_ids[idx.item()] for idx in top_indices]\n",
    "        return top_item_ids\n",
    "\n",
    "    def get_weighted_recommendations(self, user_id: str = None, *args, **kwargs) -> Dict[int, float]:\n",
    "        top_n = kwargs.get('top_n', 10)\n",
    "        user_id = int(float(user_id))\n",
    "        item_ids = dls.classes['shiur'].items[1:]\n",
    "        item_ids = [int(item_id) for item_id in item_ids]\n",
    "        user_tensor = torch.tensor([user_id] * len(item_ids)).unsqueeze(1)\n",
    "        item_tensor = torch.tensor(item_ids).unsqueeze(1)\n",
    "        input_tensor = torch.cat((user_tensor, item_tensor), dim=1)\n",
    "\n",
    "        # Get predictions\n",
    "        input_df = pd.DataFrame(input_tensor.numpy(), columns=['user', 'shiur'])\n",
    "        user_item_dl = dls.test_dl(input_df)\n",
    "        preds, _ = learn.get_preds(dl=user_item_dl)\n",
    "\n",
    "        # Get top N recommendations with their scores\n",
    "        top_indices = torch.argsort(preds, descending=True)[:top_n]\n",
    "        top_item_ids = [item_ids[idx.item()] for idx in top_indices]\n",
    "        top_scores = preds[top_indices].tolist()\n",
    "\n",
    "        recommendations = {item_id: score for item_id, score in zip(top_item_ids, top_scores)}\n",
    "        return recommendations\n",
    "\n",
    "    def get_best_shiurim(self, shiur_num:int = 10): #based on highest bias\n",
    "        shiur_bias = learn.model.i_bias.weight.squeeze()\n",
    "        idxs = shiur_bias.argsort(descending=True)[:shiur_num]\n",
    "        return [dls.classes['shiur'][i] for i in idxs]\n",
    "    \n",
    "    def get_user_bias(self, user_id:str = None):\n",
    "        user_biases = learn.model.u_bias.weight\n",
    "        user_idx = learn.dls.classes['user'].o2i[user_id]\n",
    "        return user_biases[user_idx]\n",
    "    \n",
    "    def get_shiur_bias(self, shiur_id:str = None):\n",
    "        item_biases = learn.model.i_bias.weight\n",
    "        item_idx = learn.dls.classes['user'].o2i[shiur_id]\n",
    "        return item_biases[item_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0051], grad_fn=<SelectBackward0>)\n",
      "tensor([0.0168], grad_fn=<SelectBackward0>)\n",
      "[1098754, 1098964, 1098495, 1098683, 1098108, 1097854, 1098089, 1099915, 1098832, 1098020]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1098754, 1098683, 1098495, 1099915, 1098958, 1098964, 1098832, 1098089, 1099269, 1097815]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1098754: 0.7307887673377991, 1098683: 0.7307792901992798, 1098495: 0.7307764887809753, 1099915: 0.7307316660881042, 1098958: 0.7307220101356506, 1098964: 0.7305074334144592, 1098832: 0.7305043935775757, 1098089: 0.7304328680038452, 1099269: 0.7303575873374939, 1097815: 0.7303368449211121}\n"
     ]
    }
   ],
   "source": [
    "model = UserCollabFilteringV1()\n",
    "print(model.get_shiur_bias('1098888'))\n",
    "print(model.get_user_bias('0.387775\t'))\n",
    "print(model.get_best_shiurim(10))\n",
    "print(model.get_recommendations(\"35049.0\", top_n = 10))\n",
    "print(model.get_weighted_recommendations(\"35049.0\", top_n = 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
