{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "try:\n",
    "    current_dir = os.path.dirname(__file__)\n",
    "except NameError:\n",
    "    current_dir = os.getcwd()  # Fallback to the current working directory\n",
    "\n",
    "src_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# Now import the module from utils\n",
    "from src.utils.data_layer import DataLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting Data:\n",
    "\n",
    "rating = 1 for every shiur in database. Can make something more advanced later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\n",
    "df = DataLayer.execute_query(query)\n",
    "df['rating'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fastai DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.collab import *\n",
    "\n",
    "dls = CollabDataLoaders.from_df(df, user_name='user_id', item_name='item_id', rating_name='rating', bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "learn = collab_learner(dls, n_factors=50, y_range=(0, 1), loss_func=BCEWithLogitsLossFlat())\n",
    "learn.fit_one_cycle(5, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save(\"saved_models/user_collab_filtering_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from base import BaseModel\n",
    "\n",
    "\n",
    "\n",
    "class UserCollabFilteringV1(BaseModel):\n",
    "    def __init__():\n",
    "        model = learn.load(\"../saved_models/user_collab_filtering_v1\")\n",
    "\n",
    "    def get_recommendations(self, user_id: str = None, *args, **kwargs) -> List[int]:\n",
    "        top_n = 10 if kwargs[top_n] is None else kwargs[top_n]     \n",
    "        all_item_ids = dls.classes['title'].items\n",
    "        user_idx = dls.classes['user'].o2i[user_id]\n",
    "        \n",
    "        # Create a list of user-item pairs\n",
    "        user_item_pairs = [(user_idx, dls.classes['title'].o2i[item_id]) for item_id in all_item_ids]\n",
    "        \n",
    "        # Create a DataLoader for the user-item pairs\n",
    "        user_item_dl = dls.test_dl(user_item_pairs)\n",
    "        \n",
    "        # Get predictions\n",
    "        preds, _ = learn.get_preds(dl=user_item_dl)\n",
    "        \n",
    "        # Squeeze the predictions to remove extra dimensions\n",
    "        preds = preds.squeeze()\n",
    "        \n",
    "        # Sort the predictions in descending order and get the indices\n",
    "        sorted_idxs = torch.argsort(preds, descending=True)\n",
    "        \n",
    "        # Get the top N item indices\n",
    "        top_items = [all_item_ids[i] for i in sorted_idxs[:top_n]]\n",
    "        \n",
    "        return top_items\n",
    "\n",
    "    def get_weighted_recommendations(self, user_id: str = None, *args, **kwargs) -> Dict[int, float]:\n",
    "        return super().get_weighted_recommendations(user_id, *args, **kwargs)\n",
    "    \n",
    "    def get_best_shiurim(shiur_num:int = 10): #based on highest bias\n",
    "        movie_bias = learn.model.movie_bias.squeeze()\n",
    "        idxs = movie_bias.argsort(descending=True)[:shiur_num]\n",
    "        return [dls.classes['title'][i] for i in idxs]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
