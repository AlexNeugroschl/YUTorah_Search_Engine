{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "try:\n",
    "    current_dir = os.path.dirname(__file__)\n",
    "except NameError:\n",
    "    current_dir = os.getcwd()  # Fallback to the current working directory\n",
    "\n",
    "src_dir = os.path.abspath(os.path.join(current_dir, '..', '..'))\n",
    "sys.path.append(src_dir)\n",
    "\n",
    "# Now import the module from utils\n",
    "from src.pipeline.etl import ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting Data:\n",
    "\n",
    "rating = 1 for every shiur in database. Can make something more advanced later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 18:35:07,785 - root - INFO - ETL instance created\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ETL' object has no attribute 'get_bookmakrs_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[154], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m db \u001b[38;5;241m=\u001b[39m ETL()\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bookmakrs_df\u001b[49m()\n\u001b[1;32m      3\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      4\u001b[0m df\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ETL' object has no attribute 'get_bookmakrs_df'"
     ]
    }
   ],
   "source": [
    "db = ETL()\n",
    "df = db.get_bookmakrs_df()\n",
    "df['rating'] = 1\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fastai DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>shiur</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>80580.0</td>\n",
       "      <td>1024228</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79212.0</td>\n",
       "      <td>955116</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221467.0</td>\n",
       "      <td>1079301</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92378.0</td>\n",
       "      <td>1099483</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>211439.0</td>\n",
       "      <td>1065734</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>35049.0</td>\n",
       "      <td>1012650</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>209914.0</td>\n",
       "      <td>869348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>218322.0</td>\n",
       "      <td>889236</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>212079.0</td>\n",
       "      <td>878883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10794.0</td>\n",
       "      <td>1098888</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.collab import *\n",
    "\n",
    "dls = CollabDataLoaders.from_df(df, user_name='user', item_name='shiur', rating_name='rating', bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.470572</td>\n",
       "      <td>0.469695</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.454898</td>\n",
       "      <td>0.452677</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.423188</td>\n",
       "      <td>0.422151</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.386732</td>\n",
       "      <td>0.392136</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.363057</td>\n",
       "      <td>0.372727</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.348497</td>\n",
       "      <td>0.360532</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.337910</td>\n",
       "      <td>0.352672</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.332761</td>\n",
       "      <td>0.347605</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.329789</td>\n",
       "      <td>0.344290</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.327579</td>\n",
       "      <td>0.342122</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.325411</td>\n",
       "      <td>0.340724</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.324926</td>\n",
       "      <td>0.339912</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.324502</td>\n",
       "      <td>0.339492</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.324305</td>\n",
       "      <td>0.339337</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.324493</td>\n",
       "      <td>0.339314</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "learn = collab_learner(dls, n_factors=5, y_range=(0, 1), loss_func=BCEWithLogitsLossFlat())\n",
    "learn.fit_one_cycle(15, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('saved_models/user_collab_filtering_v1.pth')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model_dir = \"saved_models/\"\n",
    "learn.save(\"user_collab_filtering_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from base import BaseModel\n",
    "\n",
    "\n",
    "\n",
    "class UserCollabFilteringV1(BaseModel):\n",
    "    def __init__(self):\n",
    "        model = learn.load(\"user_collab_filtering_v1\")\n",
    "\n",
    "    def get_recommendations(self, user_id: str = None, *args, **kwargs) -> List[int]:\n",
    "        top_n = kwargs.get('top_n', 10)\n",
    "        user_id = int(float(user_id))\n",
    "        item_ids = dls.classes['shiur'].items[1:] # to avoid the na value\n",
    "        item_ids = [int(item_id) for item_id in item_ids]\n",
    "        user_tensor = torch.tensor([user_id] * len(item_ids)).unsqueeze(1)\n",
    "        item_tensor = torch.tensor(item_ids).unsqueeze(1)\n",
    "        input_tensor = torch.cat((user_tensor, item_tensor), dim=1)\n",
    "        \n",
    "        # Get predictions\n",
    "        input_df = pd.DataFrame(input_tensor.numpy(), columns=['user', 'shiur'])\n",
    "        user_item_dl = dls.test_dl(input_df)\n",
    "        preds, _ = learn.get_preds(dl=user_item_dl)\n",
    "        \n",
    "        # Get top N recommendations\n",
    "        top_indices = torch.argsort(preds, descending=True)[:top_n]\n",
    "        top_item_ids = [item_ids[idx.item()] for idx in top_indices]\n",
    "        return top_item_ids\n",
    "\n",
    "    def get_weighted_recommendations(self, user_id: str = None, *args, **kwargs) -> Dict[int, float]:\n",
    "        top_n = kwargs.get('top_n', 10)\n",
    "        user_id = int(float(user_id))\n",
    "        item_ids = dls.classes['shiur'].items[1:]\n",
    "        item_ids = [int(item_id) for item_id in item_ids]\n",
    "        user_tensor = torch.tensor([user_id] * len(item_ids)).unsqueeze(1)\n",
    "        item_tensor = torch.tensor(item_ids).unsqueeze(1)\n",
    "        input_tensor = torch.cat((user_tensor, item_tensor), dim=1)\n",
    "\n",
    "        # Get predictions\n",
    "        input_df = pd.DataFrame(input_tensor.numpy(), columns=['user', 'shiur'])\n",
    "        user_item_dl = dls.test_dl(input_df)\n",
    "        preds, _ = learn.get_preds(dl=user_item_dl)\n",
    "\n",
    "        # Get top N recommendations with their scores\n",
    "        top_indices = torch.argsort(preds, descending=True)[:top_n]\n",
    "        top_item_ids = [item_ids[idx.item()] for idx in top_indices]\n",
    "        top_scores = preds[top_indices].tolist()\n",
    "\n",
    "        recommendations = {item_id: score for item_id, score in zip(top_item_ids, top_scores)}\n",
    "        return recommendations\n",
    "\n",
    "    def get_best_shiurim(self, shiur_num:int = 10): #based on highest bias\n",
    "        shiur_bias = learn.model.i_bias.weight.squeeze()\n",
    "        idxs = shiur_bias.argsort(descending=True)[:shiur_num]\n",
    "        return [dls.classes['shiur'][i] for i in idxs]\n",
    "    \n",
    "    def get_user_bias(self, user_id:str = None):\n",
    "        user_biases = learn.model.u_bias.weight\n",
    "        user_idx = learn.dls.classes['user'].o2i[user_id]\n",
    "        return user_biases[user_idx]\n",
    "    \n",
    "    def get_shiur_bias(self, shiur_id:str = None):\n",
    "        item_biases = learn.model.i_bias.weight\n",
    "        item_idx = learn.dls.classes['user'].o2i[shiur_id]\n",
    "        return item_biases[item_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0008], grad_fn=<SelectBackward0>)\n",
      "tensor([3.5387e-05], grad_fn=<SelectBackward0>)\n",
      "[1098754, 1098495, 1098683, 1098679, 1099765, 1098089, 1098964, 1098020, 1097854, 1098108]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1098754, 1098495, 1098683, 1098964, 1097854, 1098089, 1098108, 1098020, 1098832, 1098342]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1097854: 0.7310585975646973, 1098495: 0.7310585975646973, 1098964: 0.7310585975646973, 1098089: 0.7310585975646973, 1098754: 0.7310585975646973, 1099332: 0.7310585975646973, 1098832: 0.7310585975646973, 1098020: 0.7310585975646973, 1098108: 0.7310585975646973, 1098958: 0.7310585975646973}\n"
     ]
    }
   ],
   "source": [
    "model = UserCollabFilteringV1()\n",
    "print(model.get_shiur_bias('1098888'))\n",
    "print(model.get_user_bias('0.387775\t'))\n",
    "print(model.get_best_shiurim(10))\n",
    "print(model.get_recommendations(\"92378.0\", top_n = 10))\n",
    "print(model.get_weighted_recommendations(\"35049.0\", top_n = 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
