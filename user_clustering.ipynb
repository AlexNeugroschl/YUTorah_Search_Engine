{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from src.models.content_handler_v1 import ContentHandler\n",
    "from sklearn.decomposition import PCA\n",
    "from src.pipeline.data_processor import DataProcessor, CleanedData\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = DataProcessor()\n",
    "bookmarks_df = dp.load_table(CleanedData.BOOKMARKS)\n",
    "cat_df = dp.load_table(CleanedData.CATEGORIES)\n",
    "shiur_df = dp.load_table(CleanedData.SHIURIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_played = bookmarks_df[(bookmarks_df['played'] == 1) | (bookmarks_df['bookmark'] == 'queue')]\n",
    "user_grouped = df_played.groupby('user')\n",
    "unique_listens_per_user = df_played.groupby('user')['shiur'].nunique().reset_index()\n",
    "unique_listens_per_user['shiur'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_listens_per_user.columns = ['user', 'unique_listens']\n",
    "# Calculate IQR and filter out outliers\n",
    "Q1 = unique_listens_per_user['unique_listens'].quantile(0.00)\n",
    "Q3 = unique_listens_per_user['unique_listens'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "upper_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_listeners = unique_listens_per_user[(unique_listens_per_user['unique_listens'] <= upper_bound)]\n",
    "top_listeners = unique_listens_per_user[(unique_listens_per_user['unique_listens'] > upper_bound)]\n",
    "\n",
    "majority_listeners_list = majority_listeners['user'].unique()\n",
    "top_listeners_list = top_listeners['user'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ch = ContentHandler()\n",
    "user_embeddings_df = ch.get_user_embedding()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_user_embeddings_df = user_embeddings_df[user_embeddings_df['user'].isin(majority_listeners_list)].copy()\n",
    "top_users_embeddings_df = user_embeddings_df[user_embeddings_df['user'].isin(top_listeners_list)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shiur_embeddings(shiur_df):\n",
    "    embeddings = []\n",
    "    for index, row in shiur_df.iterrows():\n",
    "        details = row['full_details']\n",
    "        embedding = ch.get_title_vector(details)\n",
    "        embeddings.append(embedding)\n",
    "    shiur_df['embedding'] = embeddings\n",
    "    return shiur_df\n",
    "\n",
    "all_shiur_embeddings = generate_shiur_embeddings(shiur_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_length = bookmarks_df.groupby('user')['duration'].mean().reset_index()\n",
    "average_length.columns = ['user', 'average_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_listens = bookmarks_df[bookmarks_df['played'] ==  1].groupby('user').size().reset_index(name='total_listens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_listens.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge bookmarks_df with cat_df to get the categories for each listened shiur\n",
    "user_categories = bookmarks_df[['user', 'shiur']].merge(cat_df, on='shiur')\n",
    "\n",
    "user_categories.drop(columns=['shiur'],inplace=True)\n",
    "# Calculate the mean of one-hot encoded categories for each user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_preferences = user_categories.groupby('user').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_n = 5\n",
    "top_categories = category_preferences.apply(lambda x: x.nlargest(top_n).index.tolist(), axis=1).reset_index()\n",
    "top_categories.columns = ['user', 'top_categories']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_categories_exploded = top_categories.explode('top_categories')\n",
    "\n",
    "# One-hot encode the top categories\n",
    "category_counts = top_categories_exploded['top_categories'].value_counts().to_dict()\n",
    "top_categories_exploded['top_categories_encoded'] = top_categories_exploded['top_categories'].map(category_counts)\n",
    "\n",
    "# Aggregate the encoded values for each user (e.g., sum or mean)\n",
    "top_category_features = top_categories_exploded.groupby('user')['top_categories_encoded'].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "\n",
    "def calculate_entropy(row):\n",
    "    # Avoid calculating entropy on all-zero rows\n",
    "    row_non_zero = row[row > 0]\n",
    "    return entropy(row_non_zero)\n",
    "\n",
    "# Apply entropy calculation to each row (excluding the 'user' column)\n",
    "category_preferences = category_preferences.div(category_preferences.sum(axis=1), axis=0)\n",
    "diversity_df = category_preferences.apply(calculate_entropy, axis=1).reset_index()\n",
    "diversity_df.columns = ['user', 'diversity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_users_diversity(diversity_df):\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(diversity_df['diversity'], bins=30, edgecolor='k', alpha=0.7)\n",
    "    plt.title('Distribution of Diversity (Entropy) Scores for All Users')\n",
    "    plt.xlabel('Diversity (Entropy)')\n",
    "    plt.ylabel('Number of Users')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_all_users_diversity(diversity_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_df = majority_user_embeddings_df.copy()\n",
    "new_features_df = new_features_df.merge(average_length, on='user', how='left')\n",
    "new_features_df = new_features_df.merge(top_category_features, on='user', how='left')\n",
    "new_features_df = new_features_df.merge(diversity_df, on='user', how='left')\n",
    "new_features_df.fillna(0, inplace=True)\n",
    "\n",
    "new_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "embedding_pca = PCA(n_components=5)  # Adjust the number of components as needed\n",
    "embeddings = embedding_pca.fit_transform(np.stack(new_features_df['embedding'].values))\n",
    "additional_features = new_features_df.drop(columns=['user', 'embedding'])\n",
    "scaler = StandardScaler()\n",
    "normalized_features = scaler.fit_transform(additional_features)\n",
    "X = np.hstack((embeddings, normalized_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_df.drop(columns=['Cluster'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_number = 30\n",
    "kmeans = KMeans(n_clusters=cluster_number, random_state=42)\n",
    "kmeans.fit(X)\n",
    "labels = kmeans.labels_\n",
    "new_features_df.loc[:, 'Cluster'] = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_recommendations(cluster_label, user_embeddings_df, shiur_df, top_n=500):\n",
    "    cluster_embeddings = np.vstack(user_embeddings_df[user_embeddings_df['Cluster'] == cluster_label]['embedding'].values)\n",
    "    cluster_avg_embedding = np.mean(cluster_embeddings, axis=0).reshape(1, -1)\n",
    "    shiur_ids = shiur_df['shiur'].values\n",
    "    shiur_embeddings = np.vstack(shiur_df['embedding'].values)\n",
    "    similarities = cosine_similarity(cluster_avg_embedding, shiur_embeddings).flatten()\n",
    "    top_similar_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    top_similar_shiurim = [shiur_ids[i] for i in top_similar_indices]\n",
    "    return top_similar_shiurim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fine_tune_recommendations(user_id, user_embeddings_df, cluster_recommendations, shiur_df, top_n=5):\n",
    "    user_embedding = np.array(user_embeddings_df[user_embeddings_df['user'] == user_id]['embedding'].values[0]).reshape(1, -1)\n",
    "    recommended_shiur_embeddings = np.array([shiur_df[shiur_df['shiur'] == shiur]['embedding'].values[0] for shiur in cluster_recommendations])\n",
    "    similarities = cosine_similarity(user_embedding, recommended_shiur_embeddings).flatten()\n",
    "    top_similar_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    fine_tuned_recommendations = [cluster_recommendations[i] for i in top_similar_indices]\n",
    "    return fine_tuned_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_recommendations(user_id, user_embeddings_df, shiur_df, top_n=5):\n",
    "    # Check if the user_id exists in the user_embeddings_df\n",
    "    if user_id not in user_embeddings_df['user'].values:\n",
    "        raise ValueError(f\"User ID {user_id} not found in user_embeddings_df\")\n",
    "    \n",
    "    cluster_label = user_embeddings_df[user_embeddings_df['user'] == user_id]['Cluster'].values[0]\n",
    "    cluster_recommendations = get_cluster_recommendations(cluster_label, user_embeddings_df, shiur_df, top_n*2)  # Get more to fine-tune\n",
    "    fine_tuned_recommendations = fine_tune_recommendations(user_id, user_embeddings_df, cluster_recommendations, shiur_df, top_n)\n",
    "    final_recommendations = {shiur_id: shiur_df[shiur_df['shiur'] == shiur_id]['full_details'].values[0] for shiur_id in fine_tuned_recommendations}\n",
    "    \n",
    "    return final_recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_df = bookmarks_df.merge(shiur_df, on='shiur')\n",
    "info_df = info_df[['user','shiur','title', 'full_details']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_shiurs(user_id):\n",
    "    return info_df[info_df['user'] == user_id]['full_details'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 224576"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_final_recommendations(user_id, new_features_df, all_shiur_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_user_shiurs(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_category_counts = pd.DataFrame(columns=['Cluster'] + list(cat_df.columns[1:]))\n",
    "cluster_category_counts['Cluster'] = range(cluster_number)\n",
    "\n",
    "def get_category_breakdown_for_cluster(cluster_id):\n",
    "    cluster_users = new_features_df[new_features_df['Cluster'] == cluster_id]['user']\n",
    "    cluster_shiurs = bookmarks_df[bookmarks_df['user'].isin(cluster_users)]['shiur']\n",
    "    cluster_categories = cat_df[cat_df['shiur'].isin(cluster_shiurs)]\n",
    "    category_counts = cluster_categories.drop(columns='shiur').sum().to_dict()\n",
    "    return category_counts\n",
    "\n",
    "# Fill the cluster category counts DataFrame\n",
    "for i in range(cluster_number):\n",
    "    category_counts = get_category_breakdown_for_cluster(i)\n",
    "    for category, count in category_counts.items():\n",
    "        cluster_category_counts.at[i, category] = count\n",
    "\n",
    "# Fill NaN values with 0 (if any)\n",
    "cluster_category_counts.fillna(0, inplace=True)\n",
    "\n",
    "# Convert all columns to numeric to avoid issues with nlargest\n",
    "for col in cluster_category_counts.columns[1:]:\n",
    "    cluster_category_counts[col] = pd.to_numeric(cluster_category_counts[col], errors='coerce')\n",
    "\n",
    "# Save to CSV\n",
    "cluster_category_counts.to_csv(\"results.csv\")\n",
    "\n",
    "# Find top 5 categories for each cluster\n",
    "top_categories = {}\n",
    "\n",
    "for cluster in cluster_category_counts.index:\n",
    "    top_categories[cluster] = cluster_category_counts.loc[cluster, cluster_category_counts.columns != 'Cluster'].nlargest(5)\n",
    "\n",
    "# Convert to DataFrame for easier plotting\n",
    "top_categories_df = pd.DataFrame(top_categories).T\n",
    "\n",
    "# Plotting\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "num_clusters = len(top_categories_df)\n",
    "cols = 3\n",
    "rows = (num_clusters // cols) + (num_clusters % cols > 0)\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(15, 20), constrained_layout=True)\n",
    "\n",
    "for i, cluster in enumerate(top_categories_df.index):\n",
    "    row = i // cols\n",
    "    col = i % cols\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    top_categories_cluster = top_categories_df.loc[cluster]\n",
    "    top_categories_cluster = top_categories_cluster.sort_values(ascending=False)\n",
    "    \n",
    "    sns.barplot(x=top_categories_cluster.values[:5], y=top_categories_cluster.index[:5], ax=ax, hue=top_categories_cluster.index[:5], palette=\"viridis\", legend=False)\n",
    "    num_users = new_features_df[new_features_df['Cluster'] == i].count().values[0]\n",
    "    ax.set_title(f'Cluster {cluster} - {num_users} Users')\n",
    "    ax.set_xlabel('Count')\n",
    "    ax.set_ylabel('Category')\n",
    "\n",
    "# Remove any empty subplots\n",
    "for j in range(i + 1, rows * cols):\n",
    "    fig.delaxes(axes.flatten()[j])\n",
    "\n",
    "plt.suptitle('Top 5 Categories by Cluster', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "# Extract embeddings and cluster labels\n",
    "embeddings = np.stack(new_features_df['embedding'].values)\n",
    "cluster_labels = new_features_df['Cluster'].values\n",
    "\n",
    "# Perform TSNE\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_embeddings = tsne.fit_transform(embeddings)\n",
    "\n",
    "def plot_tsne_clusters(tsne_embeddings, cluster_labels, clusters_to_plot, cluster_category_counts, title='TSNE Visualization'):\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    mask = np.isin(cluster_labels, clusters_to_plot)\n",
    "    subset_embeddings = tsne_embeddings[mask]\n",
    "    subset_labels = cluster_labels[mask]\n",
    "\n",
    "    scatter = plt.scatter(subset_embeddings[:, 0], subset_embeddings[:, 1], c=subset_labels, cmap='viridis', s=50)\n",
    "    plt.legend(handles=scatter.legend_elements()[0], labels=[f'Cluster {i}' for i in clusters_to_plot], title=\"Clusters\")\n",
    "\n",
    "    # Adding text labels for each cluster based on the mean position of their embeddings\n",
    "    for cluster_id in clusters_to_plot:\n",
    "        cluster_mask = subset_labels == cluster_id\n",
    "        cluster_mean = subset_embeddings[cluster_mask].mean(axis=0)\n",
    "        categories = cluster_category_counts.loc[cluster_id].nlargest(1).index[0]\n",
    "        plt.text(cluster_mean[0], cluster_mean[1], f'Cluster {cluster_id}\\nTop: {categories}', fontsize=9, ha='center')\n",
    "\n",
    "    plt.colorbar(scatter, label='Cluster')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('TSNE Dimension 1')\n",
    "    plt.ylabel('TSNE Dimension 2')\n",
    "    plt.show()\n",
    "\n",
    "# Number of clusters\n",
    "num_clusters = len(np.unique(cluster_labels))\n",
    "\n",
    "# Number of clusters to visualize at a time\n",
    "clusters_per_plot = 5\n",
    "\n",
    "for i in range(0, num_clusters, clusters_per_plot):\n",
    "    clusters_to_plot = range(i, min(i + clusters_per_plot, num_clusters))\n",
    "    plot_tsne_clusters(tsne_embeddings, cluster_labels, clusters_to_plot, cluster_category_counts, title=f'TSNE Visualization for Clusters {i}-{i+clusters_per_plot-1}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
