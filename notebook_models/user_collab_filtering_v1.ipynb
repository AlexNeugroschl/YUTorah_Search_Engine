{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(src_dir)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Now you can import etl\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m etl\n",
      "File \u001b[0;32m/home/alex_neugroschl/Camp_CompSci/TorahNavigator/repo/Torah-Navigator/src/pipeline/etl.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdb_connection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m db_connection\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m setup_logging\n\u001b[1;32m      5\u001b[0m logger \u001b[38;5;241m=\u001b[39m setup_logging()\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the current working directory of the notebook\n",
    "notebook_dir = os.getcwd()\n",
    "\n",
    "# Add the src directory to the Python path\n",
    "src_dir = os.path.abspath(os.path.join(notebook_dir, '..', 'src'))\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "# Now you can import etl\n",
    "from pipeline import etl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting Data:\n",
    "\n",
    "rating = 1 for every shiur in database. Can make something more advanced later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-28 18:35:44,158 - root - INFO - ETL instance created\n",
      "2024-06-28 18:35:44,159 - root - INFO - START: Bookmarks Query\n",
      "2024-06-28 18:35:44,256 - root - INFO - END: Favorites Query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24677, 11)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = ETL()\n",
    "df = db.get_bookmarks_df()\n",
    "df['rating'] = 1\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fastai DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>shiur</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48586.0</td>\n",
       "      <td>720247</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49170.0</td>\n",
       "      <td>767032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37795.0</td>\n",
       "      <td>726986</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51057.0</td>\n",
       "      <td>1099721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>79749.0</td>\n",
       "      <td>733521</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>76777.0</td>\n",
       "      <td>1065957</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2479.0</td>\n",
       "      <td>1099629</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>69741.0</td>\n",
       "      <td>869664</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7725.0</td>\n",
       "      <td>761023</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37769.0</td>\n",
       "      <td>759078</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.collab import *\n",
    "\n",
    "dls = CollabDataLoaders.from_df(df, user_name='user', item_name='shiur', rating_name='rating', bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.470583</td>\n",
       "      <td>0.470057</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.454623</td>\n",
       "      <td>0.452919</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.422855</td>\n",
       "      <td>0.422133</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.387729</td>\n",
       "      <td>0.392547</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.363661</td>\n",
       "      <td>0.373325</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.348175</td>\n",
       "      <td>0.361069</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.338278</td>\n",
       "      <td>0.353237</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.332768</td>\n",
       "      <td>0.348102</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.328935</td>\n",
       "      <td>0.344708</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.327235</td>\n",
       "      <td>0.342509</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.325898</td>\n",
       "      <td>0.341119</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.324495</td>\n",
       "      <td>0.340292</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.324538</td>\n",
       "      <td>0.339883</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.324293</td>\n",
       "      <td>0.339728</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.324014</td>\n",
       "      <td>0.339704</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "learn = collab_learner(dls, n_factors=5, y_range=(0, 1), loss_func=BCEWithLogitsLossFlat())\n",
    "learn.fit_one_cycle(15, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('saved_models/user_collab_filtering_v1.pth')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.model_dir = \"saved_models/\"\n",
    "learn.save(\"user_collab_filtering_v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "from base import BaseModel\n",
    "\n",
    "\n",
    "\n",
    "class UserCollabFilteringV1(BaseModel):\n",
    "    def __init__(self):\n",
    "        model = learn.load(\"user_collab_filtering_v1\")\n",
    "\n",
    "    def get_recommendations(self, user_id: str = None, *args, **kwargs) -> List[int]:\n",
    "        top_n = kwargs.get('top_n', 10)\n",
    "        user_id = int(float(user_id))\n",
    "        item_ids = dls.classes['shiur'].items[1:] # to avoid the na value\n",
    "        item_ids = [int(item_id) for item_id in item_ids]\n",
    "        user_tensor = torch.tensor([user_id] * len(item_ids)).unsqueeze(1)\n",
    "        item_tensor = torch.tensor(item_ids).unsqueeze(1)\n",
    "        input_tensor = torch.cat((user_tensor, item_tensor), dim=1)\n",
    "        \n",
    "        # Get predictions\n",
    "        input_df = pd.DataFrame(input_tensor.numpy(), columns=['user', 'shiur'])\n",
    "        user_item_dl = dls.test_dl(input_df)\n",
    "        preds, _ = learn.get_preds(dl=user_item_dl)\n",
    "        \n",
    "        # Get top N recommendations\n",
    "        top_indices = torch.argsort(preds, descending=True)[:top_n]\n",
    "        top_item_ids = [item_ids[idx.item()] for idx in top_indices]\n",
    "        return top_item_ids\n",
    "\n",
    "    def get_weighted_recommendations(self, user_id: str = None, *args, **kwargs) -> Dict[int, float]:\n",
    "        top_n = kwargs.get('top_n', 10)\n",
    "        user_id = int(float(user_id))\n",
    "        item_ids = dls.classes['shiur'].items[1:]\n",
    "        item_ids = [int(item_id) for item_id in item_ids]\n",
    "        user_tensor = torch.tensor([user_id] * len(item_ids)).unsqueeze(1)\n",
    "        item_tensor = torch.tensor(item_ids).unsqueeze(1)\n",
    "        input_tensor = torch.cat((user_tensor, item_tensor), dim=1)\n",
    "\n",
    "        # Get predictions\n",
    "        input_df = pd.DataFrame(input_tensor.numpy(), columns=['user', 'shiur'])\n",
    "        user_item_dl = dls.test_dl(input_df)\n",
    "        preds, _ = learn.get_preds(dl=user_item_dl)\n",
    "\n",
    "        # Get top N recommendations with their scores\n",
    "        top_indices = torch.argsort(preds, descending=True)[:top_n]\n",
    "        top_item_ids = [item_ids[idx.item()] for idx in top_indices]\n",
    "        top_scores = preds[top_indices].tolist()\n",
    "\n",
    "        recommendations = {item_id: score for item_id, score in zip(top_item_ids, top_scores)}\n",
    "        return recommendations\n",
    "\n",
    "    def get_best_shiurim(self, shiur_num:int = 10): #based on highest bias\n",
    "        shiur_bias = learn.model.i_bias.weight.squeeze()\n",
    "        idxs = shiur_bias.argsort(descending=True)[:shiur_num]\n",
    "        return [dls.classes['shiur'][i] for i in idxs]\n",
    "    \n",
    "    def get_user_bias(self, user_id:str = None):\n",
    "        user_biases = learn.model.u_bias.weight\n",
    "        user_idx = learn.dls.classes['user'].o2i[user_id]\n",
    "        return user_biases[user_idx]\n",
    "    \n",
    "    def get_shiur_bias(self, shiur_id:str = None):\n",
    "        item_biases = learn.model.i_bias.weight\n",
    "        item_idx = learn.dls.classes['user'].o2i[shiur_id]\n",
    "        return item_biases[item_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0084], grad_fn=<SelectBackward0>)\n",
      "tensor([-0.0045], grad_fn=<SelectBackward0>)\n",
      "[1098495, 1098754, 1098342, 1098683, 1098964, 1097854, 1099765, 1098108, 1098089, 1097678]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1098754, 1098495, 1098683, 1098342, 1098964, 1097854, 1098108, 1098089, 1099332, 1097846]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1098089: 0.7310585975646973, 1097854: 0.7310585975646973, 1098683: 0.7310585975646973, 1098958: 0.7310585975646973, 1099697: 0.7310585975646973, 1097846: 0.7310585975646973, 1099915: 0.7310585975646973, 1098108: 0.7310585975646973, 1099332: 0.7310585975646973, 1097815: 0.7310585975646973}\n"
     ]
    }
   ],
   "source": [
    "model = UserCollabFilteringV1()\n",
    "print(model.get_shiur_bias('1098888'))\n",
    "print(model.get_user_bias('0.387775\t'))\n",
    "print(model.get_best_shiurim(10))\n",
    "print(model.get_recommendations(\"92378.0\", top_n = 10))\n",
    "print(model.get_weighted_recommendations(\"35049.0\", top_n = 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
