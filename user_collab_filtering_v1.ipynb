{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "user_collab_filtering_v1\n",
    "Not very good but a model for things to come"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.pipeline.etl import ETL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collecting Data:\n",
    "\n",
    "rating = 1 for every shiur in database. Can make something more advanced later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-01 15:37:33,523 - root - INFO - ETL instance created\n",
      "2024-07-01 15:37:33,526 - root - INFO - START: Bookmarks Query\n",
      "2024-07-01 15:37:33,609 - root - INFO - END: Favorites Query\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(24677, 11)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = ETL()\n",
    "df = db.get_bookmarks_df()\n",
    "df['rating'] = 1\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create fastai DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>shiur</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>76419.0</td>\n",
       "      <td>779703</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222432.0</td>\n",
       "      <td>1098871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>221727.0</td>\n",
       "      <td>911338</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60237.0</td>\n",
       "      <td>823587</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42791.0</td>\n",
       "      <td>1040452</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>73344.0</td>\n",
       "      <td>810334</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>206438.0</td>\n",
       "      <td>1065503</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33951.0</td>\n",
       "      <td>957893</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>64504.0</td>\n",
       "      <td>1097599</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>218322.0</td>\n",
       "      <td>878627</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.collab import *\n",
    "\n",
    "dls = CollabDataLoaders.from_df(df, user_name='user', item_name='shiur', rating_name='rating', bs=64)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.470534</td>\n",
       "      <td>0.469944</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.454549</td>\n",
       "      <td>0.452904</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.422484</td>\n",
       "      <td>0.422224</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.387753</td>\n",
       "      <td>0.392311</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.363628</td>\n",
       "      <td>0.372793</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.347531</td>\n",
       "      <td>0.360531</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.339118</td>\n",
       "      <td>0.352830</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.333309</td>\n",
       "      <td>0.347701</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.330216</td>\n",
       "      <td>0.344303</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.327266</td>\n",
       "      <td>0.342107</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.325668</td>\n",
       "      <td>0.340667</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.324707</td>\n",
       "      <td>0.339841</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.324784</td>\n",
       "      <td>0.339419</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.324497</td>\n",
       "      <td>0.339263</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.324681</td>\n",
       "      <td>0.339241</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from fastai.vision.all import *\n",
    "\n",
    "learn = collab_learner(dls, n_factors=5, y_range=(0, 1), loss_func=BCEWithLogitsLossFlat())\n",
    "learn.fit_one_cycle(15, 5e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export(\"saved_models/user_collab_filtering_v1.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "\n",
    "\n",
    "class UserCollabFilteringV1:\n",
    "    def __init__(self):\n",
    "        model = load_learner(\"saved_models/user_collab_filtering_v1.pkl\")\n",
    "\n",
    "    def get_recommendations(self, user_id: str = None, *args, **kwargs) -> List[int]:\n",
    "        top_n = kwargs.get('top_n', 10)\n",
    "        user_id = int(float(user_id))\n",
    "        item_ids = dls.classes['shiur'].items[1:] # to avoid the na value\n",
    "        item_ids = [int(item_id) for item_id in item_ids]\n",
    "        user_tensor = torch.tensor([user_id] * len(item_ids)).unsqueeze(1)\n",
    "        item_tensor = torch.tensor(item_ids).unsqueeze(1)\n",
    "        input_tensor = torch.cat((user_tensor, item_tensor), dim=1)\n",
    "        \n",
    "        # Get predictions\n",
    "        input_df = pd.DataFrame(input_tensor.numpy(), columns=['user', 'shiur'])\n",
    "        user_item_dl = dls.test_dl(input_df)\n",
    "        preds, _ = learn.get_preds(dl=user_item_dl)\n",
    "        \n",
    "        # Get top N recommendations\n",
    "        top_indices = torch.argsort(preds, descending=True)[:top_n]\n",
    "        top_item_ids = [item_ids[idx.item()] for idx in top_indices]\n",
    "        return top_item_ids\n",
    "\n",
    "    def get_weighted_recommendations(self, user_id: str = None, *args, **kwargs) -> Dict[int, float]:\n",
    "        top_n = kwargs.get('top_n', 10)\n",
    "        user_id = int(float(user_id))\n",
    "        item_ids = dls.classes['shiur'].items[1:]\n",
    "        item_ids = [int(item_id) for item_id in item_ids]\n",
    "        user_tensor = torch.tensor([user_id] * len(item_ids)).unsqueeze(1)\n",
    "        item_tensor = torch.tensor(item_ids).unsqueeze(1)\n",
    "        input_tensor = torch.cat((user_tensor, item_tensor), dim=1)\n",
    "\n",
    "        # Get predictions\n",
    "        input_df = pd.DataFrame(input_tensor.numpy(), columns=['user', 'shiur'])\n",
    "        user_item_dl = dls.test_dl(input_df)\n",
    "        preds, _ = learn.get_preds(dl=user_item_dl)\n",
    "\n",
    "        # Get top N recommendations with their scores\n",
    "        top_indices = torch.argsort(preds, descending=True)[:top_n]\n",
    "        top_item_ids = [item_ids[idx.item()] for idx in top_indices]\n",
    "        top_scores = preds[top_indices].tolist()\n",
    "\n",
    "        recommendations = {item_id: score for item_id, score in zip(top_item_ids, top_scores)}\n",
    "        return recommendations\n",
    "\n",
    "    def get_best_shiurim(self, shiur_num:int = 10): #based on highest bias\n",
    "        shiur_bias = learn.model.i_bias.weight.squeeze()\n",
    "        idxs = shiur_bias.argsort(descending=True)[:shiur_num]\n",
    "        return [dls.classes['shiur'][i] for i in idxs]\n",
    "    \n",
    "    def get_user_bias(self, user_id:str = None):\n",
    "        user_biases = learn.model.u_bias.weight\n",
    "        user_idx = learn.dls.classes['user'].o2i[user_id]\n",
    "        return user_biases[user_idx]\n",
    "    \n",
    "    def get_shiur_bias(self, shiur_id:str = None):\n",
    "        item_biases = learn.model.i_bias.weight\n",
    "        item_idx = learn.dls.classes['user'].o2i[shiur_id]\n",
    "        return item_biases[item_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.0063], grad_fn=<SelectBackward0>)\n",
      "tensor([-0.0062], grad_fn=<SelectBackward0>)\n",
      "[1098754, 1098495, 1098683, 1098964, 1098089, 1098679, 1098108, 1098832, 1097854, 1098342]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1098754, 1098683, 1098964, 1098495, 1098108, 1098832, 1098089, 1098342, 1097854, 1098020]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1098108: 0.7310585975646973, 1098683: 0.7310585975646973, 1098342: 0.7310585975646973, 1097854: 0.7310585975646973, 1098754: 0.7310585975646973, 1098832: 0.7310585975646973, 1098964: 0.7310585975646973, 1099915: 0.7310585379600525, 1098495: 0.7310585379600525, 1098574: 0.7310585379600525}\n"
     ]
    }
   ],
   "source": [
    "model = UserCollabFilteringV1()\n",
    "print(model.get_shiur_bias('1098888'))\n",
    "print(model.get_user_bias('0.387775\t'))\n",
    "print(model.get_best_shiurim(10))\n",
    "print(model.get_recommendations(\"92378.0\", top_n = 10))\n",
    "print(model.get_weighted_recommendations(\"35049.0\", top_n = 10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
